{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch as t\n",
    "from m4.data.dataset_extractor import M4DatasetExtractor, M4DatasetGroup\n",
    "from fcast.utils.serialization import deserialize\n",
    "from m4.pipeline.forecaster.m4_baselines import theta\n",
    "from fcast.pipeline.transformation.scaling import Scaling\n",
    "from m4.pipeline.model.lstm import UniqueLSTM\n",
    "from fcast.domain.dataset import Dataset\n",
    "from m4.pipeline.adaptors import dataframe_to_tensor, default_torch_device, tensor_to_dataframe\n",
    "from pandas import DataFrame\n",
    "\n",
    "def df_to_tensor(df):\n",
    "    return t.unsqueeze(dataframe_to_tensor(df), 0)\n",
    "\n",
    "def tensor_to_df(tensor, df):\n",
    "    return tensor_to_dataframe(t.squeeze(tensor, 0), df.columns)\n",
    "\n",
    "def minmax_scale(df):\n",
    "    min_v = float(df.min(axis=0))\n",
    "    max_v = float(df.max(axis=0))\n",
    "    denominator = max_v - min_v\n",
    "    return df.apply(lambda v: (v - min_v) / denominator)\n",
    "\n",
    "\n",
    "extractor = M4DatasetExtractor(dataset_path='/projects/eai-m4/dataset', group=M4DatasetGroup.daily)\n",
    "train_dataset = extractor.training_set()\n",
    "ts = train_dataset[1].data\n",
    "\n",
    "input_ts = minmax_scale(ts)\n",
    "\n",
    "\n",
    "print(f'original: {ts.shape}\\ninput ts shape: {input_ts.shape}\\ninput tensor shape: {df_to_tensor(input_ts).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSLSTM(t.nn.Module):\n",
    "    def __init__(self, name, hidden_size, num_layers, optim, loss):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.name = name\n",
    "        self.optim = optim\n",
    "        self.loss = loss\n",
    "        \n",
    "        self.lstm = t.nn.LSTM(input_size=1,\n",
    "                              hidden_size=hidden_size,\n",
    "                              num_layers=num_layers,\n",
    "                              batch_first=True  # expects input as (batch, seq, features)\n",
    "                             )\n",
    "        self.output_layer = t.nn.Linear(in_features=hidden_size, out_features=1)                          \n",
    "        \n",
    "    def update(self, df):\n",
    "        x = df_to_tensor(df)\n",
    "        optim = self.optim(self.parameters())\n",
    "        loss = t.nn.L1Loss(reduction='elementwise_mean')\n",
    "        prediction = self(x[:, :-1, :])\n",
    "        loss_fn = loss(prediction, x[:, 1:, :])\n",
    "        loss_fn.backward() # calculates gradients for each model parameter (looking at prediction)\n",
    "        optim.step() # updates weights\n",
    "        return float(loss_fn)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "    \n",
    "    def predict(self, df):\n",
    "        return tensor_to_df(self(df_to_tensor(df)), df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pylab as plt\n",
    "from IPython import display\n",
    "\n",
    "def train(models):\n",
    "    losses = dict([(model.name, []) for model in models])\n",
    "    predictions = dict([(model.name, []) for model in models])\n",
    "    \n",
    "    while True:      \n",
    "        for model in models:\n",
    "            losses[model.name] += [model.update(input_ts)]\n",
    "            predictions[model.name] = model.predict(input_ts)                \n",
    "        \n",
    "        plt.figure(num=1, figsize=(16, 8), dpi=120)\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.plot(input_ts, label='original')\n",
    "        for model in models:\n",
    "            plt.plot(predictions[model.name], label=model.name)\n",
    "        plt.legend()        \n",
    "        f1 = plt.gcf()\n",
    "\n",
    "        plt.figure(num=2, figsize=(16, 8), dpi=120)\n",
    "        plt.clf()\n",
    "        for model in models:            \n",
    "            plt.plot(losses[model.name], label=model.name)\n",
    "        plt.legend()\n",
    "        f2 = plt.gcf()\n",
    "        \n",
    "        f1.canvas.draw()                    \n",
    "        f2.canvas.draw()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = TSLSTM('sgd', 100, 1, lambda p: t.optim.SGD(p, lr=0.001), t.nn.L1Loss(reduction='elementwise_mean'))\n",
    "adam = TSLSTM('adam', 100, 1, lambda p: t.optim.Adam(p), t.nn.L1Loss(reduction='elementwise_mean'))\n",
    "\n",
    "train([adam, sgd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
